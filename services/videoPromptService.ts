/**
 * Video Prompt Generation Service
 * å‹•ç”»ç”Ÿæˆç”¨ã®è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç›´æ¥ç”Ÿæˆã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹
 */

import { PromptScene } from '../types';

interface VideoPromptRequest {
  lyrics: string;
  style: string;
  model: string;
  existingScenes?: PromptScene[];  // å­—ã‚³ãƒ³ãƒ†ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
}

interface VideoScene {
  scene: number;
  timestamp: string;
  duration_seconds: number;
  prompt: string;
  negative_prompt: string;
}

/**
 * æ­Œè©ã‹ã‚‰å‹•ç”»ç”Ÿæˆç”¨ã®è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç›´æ¥ç”Ÿæˆ
 */
export async function generateVideoPrompts(
  apiKey: string,
  request: VideoPromptRequest
): Promise<VideoScene[]> {
  
  // å­—ã‚³ãƒ³ãƒ†ãŒã‚ã‚‹å ´åˆã¯ã€ãã‚Œã‚’åŸºã«ç”Ÿæˆ
  const sceneCount = request.existingScenes?.length || 0;
  const hasExistingScenes = sceneCount > 0;
  
  const systemPrompt = `You are a professional storyboard artist and cinematographer specializing in music video production. Your task is to create detailed, technical English prompts for AI video generation (WAN Text-to-Video model).

CRITICAL REQUIREMENTS:
1. Generate prompts in ENGLISH ONLY (no Japanese)
2. Each prompt must be 150-300 words with technical cinematography details
3. Include: camera angles, movements, lighting, color grading, composition, mood
4. Output format: JSON array with scene, timestamp, duration_seconds, prompt, negative_prompt
5. ${hasExistingScenes ? `ğŸš¨ ABSOLUTE REQUIREMENT: Generate EXACTLY ${sceneCount} scenes - one for each provided scene description. COUNT your output before finishing. If you generate fewer than ${sceneCount} scenes, you FAILED.` : 'ğŸš¨ ABSOLUTE REQUIREMENT: Generate ALL scenes based on lyrics length (every 2-4 lines = 1 scene). Do NOT truncate or stop early.'}

${hasExistingScenes ? `SCENE COUNT VERIFICATION:
- Input: ${sceneCount} storyboard scenes
- Output: MUST be ${sceneCount} JSON objects
- Before submitting, verify: scenes.length === ${sceneCount}
- If incomplete, continue generating remaining scenes` : ''}

PROMPT STRUCTURE (for each scene):
- Camera: angle (eye-level/low/high), movement (static/pan/dolly), lens (wide/medium/close-up)
- Subject: character description, action, expression
- Background: environment, depth of field
- Lighting: type (natural/artificial), direction, color temperature
- Color Grading: color palette, contrast, film look
- Mood: atmosphere, emotion
- Technical: 832x480, 24fps, cinematic

NEGATIVE PROMPT (standard):
"blurry, low quality, distorted, deformed, ugly, static, messy, amateur"

EXAMPLE OUTPUT:
{
  "scene": 1,
  "timestamp": "0:00-0:04",
  "duration_seconds": 4,
  "prompt": "Cinematic medium shot at eye level, young man (late 20s, casual outfit) standing on urban street at golden hour. Background shows blurred city buildings with warm sunset glow. Soft natural lighting from left creates gentle shadows. Color palette: warm oranges and deep blues, high contrast. Mood: contemplative and hopeful. Camera static, shallow depth of field (f/2.8), 832x480, 24fps, cinematic bokeh.",
  "negative_prompt": "blurry, low quality, distorted, deformed, ugly, static, messy, amateur"
}`;

  let userPrompt = '';
  
  if (hasExistingScenes && request.existingScenes) {
    // å­—ã‚³ãƒ³ãƒ†ãƒ™ãƒ¼ã‚¹ã®ç”Ÿæˆ
    const sceneDescriptions = request.existingScenes.map((scene, index) => 
      `Scene ${index + 1} (${scene.duration}): ${scene.cutDescription}`
    ).join('\n\n');
    
    userPrompt = `Generate ${sceneCount} technical English video prompts based on these storyboard scenes.

STORYBOARD SCENES:
${sceneDescriptions}

VISUAL STYLE: ${request.style}

INSTRUCTIONS:
1. Generate EXACTLY ${sceneCount} scenes - one for each scene above
2. Each scene duration: extract from the storyboard duration
3. For EACH scene, create a 150-300 word technical English prompt with:
   - Camera setup (angle, movement, lens)
   - Subject details based on the scene description
   - Background and environment
   - Lighting (type, direction, temperature)
   - Color grading (palette, contrast)
   - Mood and atmosphere
4. Use standard negative_prompt for all scenes
5. Return ONLY valid JSON array - NO markdown code blocks, NO extra text

CRITICAL: Generate ALL ${sceneCount} scenes. Do not skip any scenes.

OUTPUT FORMAT:
[
  { "scene": 1, "timestamp": "0:00-0:04", "duration_seconds": 4, "prompt": "150-300 word English prompt...", "negative_prompt": "..." },
  { "scene": 2, "timestamp": "0:04-0:08", "duration_seconds": 4, "prompt": "150-300 word English prompt...", "negative_prompt": "..." },
  ...
  { "scene": ${sceneCount}, "timestamp": "...", "duration_seconds": 4, "prompt": "150-300 word English prompt...", "negative_prompt": "..." }
]`;
  } else {
    // æ­Œè©ãƒ™ãƒ¼ã‚¹ã®ç”Ÿæˆï¼ˆå¾“æ¥é€šã‚Šï¼‰
    userPrompt = `Generate a music video storyboard with technical English prompts for AI video generation.

LYRICS:
${request.lyrics}

VISUAL STYLE: ${request.style}

INSTRUCTIONS:
1. Count lyric lines and create 1 scene per 2-4 lines (e.g., 16 lines = 4-8 scenes, 32 lines = 8-16 scenes)
2. Each scene duration: 3-5 seconds
3. For EACH scene, create a 150-300 word technical English prompt with:
   - Camera setup (angle, movement, lens)
   - Subject details (appearance, action)
   - Background (environment, depth)
   - Lighting (type, direction, temperature)
   - Color grading (palette, contrast)
   - Mood and atmosphere
4. Use standard negative_prompt for all scenes
5. Return ONLY valid JSON array - NO markdown code blocks, NO extra text

CRITICAL: Generate ALL scenes needed for the full lyrics. Do not truncate.

OUTPUT FORMAT (example for 2 scenes):
[
  {
    "scene": 1,
    "timestamp": "0:00-0:04",
    "duration_seconds": 4,
    "prompt": "150-300 word English prompt with camera, subject, background, lighting, color, mood...",
    "negative_prompt": "blurry, low quality, distorted, deformed, ugly, static, messy, amateur"
  },
  {
    "scene": 2,
    "timestamp": "0:04-0:08",
    "duration_seconds": 4,
    "prompt": "150-300 word English prompt with camera, subject, background, lighting, color, mood...",
    "negative_prompt": "blurry, low quality, distorted, deformed, ugly, static, messy, amateur"
  }
]`;
  }

  // ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãAPIã‚³ãƒ¼ãƒ«
  let lastError: Error | null = null;
  const maxRetries = 3;  // å¢—åŠ : 502ã‚¨ãƒ©ãƒ¼å¯¾ç­–
  const retryDelay = 5000; // å¢—åŠ : 5ç§’ï¼ˆã‚µãƒ¼ãƒãƒ¼å›å¾©å¾…ã¡ï¼‰

  console.log(`ğŸ¬ å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆé–‹å§‹`);
  console.log(`ğŸ“Š ã‚·ãƒ¼ãƒ³æ•°: ${hasExistingScenes ? sceneCount : 'æ­Œè©ã‹ã‚‰è‡ªå‹•è¨ˆç®—'}`);
  console.log(`ğŸ¤– ãƒ¢ãƒ‡ãƒ«: ${request.model}`);
  console.log(`ğŸ“ max_tokens: 50000 (é•·æ–‡å¿œç­”ã‚µãƒãƒ¼ãƒˆ)`);

  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      if (attempt > 0) {
        console.log(`ğŸ”„ ãƒªãƒˆãƒ©ã‚¤ ${attempt}/${maxRetries}...`);
        await new Promise(resolve => setTimeout(resolve, retryDelay));
      }

      console.log(`ğŸš€ OpenRouter APIå‘¼ã³å‡ºã—ä¸­... (è©¦è¡Œ ${attempt + 1})`);

      const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json',
          'HTTP-Referer': window.location.origin,
          'X-Title': 'LyricToPrompt AI Studio'
        },
        body: JSON.stringify({
          model: request.model,
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userPrompt }
          ],
          temperature: 0.7,
          max_tokens: 50000  // å¢—åŠ : ã‚ˆã‚Šé•·ã„å¿œç­”ã‚’ã‚µãƒãƒ¼ãƒˆ
        })
      });

      console.log(`ğŸ“¡ APIå¿œç­”: ${response.status} ${response.statusText}`);

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        const errorMessage = errorData.error?.message || `HTTP ${response.status}`;
        
        console.error(`âŒ APIã‚¨ãƒ©ãƒ¼: ${errorMessage}`);
        
        // 502, 503, 504ã‚¨ãƒ©ãƒ¼ï¼ˆã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ï¼‰ã‚‚ãƒªãƒˆãƒ©ã‚¤å¯¾è±¡
        if ([429, 502, 503, 504].includes(response.status) && attempt < maxRetries) {
          const errorType = response.status === 429 ? 'ãƒ¬ãƒ¼ãƒˆåˆ¶é™' : 'ã‚µãƒ¼ãƒãƒ¼';
          lastError = new Error(`${errorType}ã‚¨ãƒ©ãƒ¼ (${response.status}): ${errorMessage}`);
          console.warn(`â³ ${errorType}ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚${retryDelay/1000}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...`);
          continue;
        }
        
        // ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼
        let friendlyMessage = errorMessage;
        if (response.status === 429) {
          friendlyMessage = `â³ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼: ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå¤šã™ãã¾ã™ã€‚\n\nğŸ’¡ å¯¾å‡¦æ³•ï¼š\n- æ•°åˆ†å¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œ\n- åˆ¥ã®ç„¡æ–™ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ\n- æœ‰æ–™ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ãŒç·©ã„ï¼‰`;
        } else if (errorMessage.includes('Provider returned error') || errorMessage.includes('No endpoints found')) {
          friendlyMessage = `ğŸš« ãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ©ãƒ¼: ${request.model}ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\n\nğŸ’¡ å¯¾å‡¦æ³•ï¼š\n- åˆ¥ã®ç„¡æ–™ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„\n- æ¨å¥¨ãƒ¢ãƒ‡ãƒ«:\n  1ï¸âƒ£ DeepSeek R1T Chimera (tngtech/deepseek-r1t-chimera:free)\n  2ï¸âƒ£ Amazon Nova 2 Lite (amazon/nova-2-lite:free)\n  3ï¸âƒ£ OpenAI GPT-OSS 20B (openai/gpt-oss-20b:free)`;
        } else if (response.status === 404) {
          friendlyMessage = `âŒ 404ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n\nãƒ¢ãƒ‡ãƒ«ID: ${request.model}\n\nğŸ’¡ OpenRouterã§åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèª:\nhttps://openrouter.ai/models?q=free\n\næ¨å¥¨: DeepSeek R1T Chimera (tngtech/deepseek-r1t-chimera:free)`;
        }
        
        throw new Error(`OpenRouter API error: ${friendlyMessage}\n\nModel: ${request.model}\n\nåˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«: https://openrouter.ai/models`);
      }

      const data = await response.json();
      const content = data.choices[0].message.content;

      console.log(`ğŸ“¦ ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡ (é•·ã•: ${content.length} æ–‡å­—)`);
      console.log(`ğŸ“ ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: ${content.substring(0, 200)}...`);

      // JSONã‚’æŠ½å‡ºï¼ˆãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’å‰Šé™¤ï¼‰
      let jsonContent = content.trim();
      
      // ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®é™¤å»
      jsonContent = jsonContent.replace(/```json\s*/g, '').replace(/```\s*/g, '');
      
      // å‰å¾Œã®ä½™åˆ†ãªãƒ†ã‚­ã‚¹ãƒˆã‚’å‰Šé™¤ï¼ˆJSONã®é–‹å§‹ã¨çµ‚äº†ã‚’æ¤œå‡ºï¼‰
      const jsonStart = jsonContent.indexOf('[');
      const jsonEnd = jsonContent.lastIndexOf(']');
      
      if (jsonStart !== -1 && jsonEnd !== -1) {
        jsonContent = jsonContent.substring(jsonStart, jsonEnd + 1);
      }

      console.log(`ğŸ” JSONæŠ½å‡ºå®Œäº† (é•·ã•: ${jsonContent.length} æ–‡å­—)`);

      const scenes: VideoScene[] = JSON.parse(jsonContent);

      // ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
      if (!Array.isArray(scenes) || scenes.length === 0) {
        throw new Error('Invalid scene data returned');
      }

      console.log(`âœ… Generated ${scenes.length} scenes successfully`);
      
      if (hasExistingScenes && scenes.length !== sceneCount) {
        console.warn(`âš ï¸ ã‚·ãƒ¼ãƒ³æ•°ä¸ä¸€è‡´: æœŸå¾…=${sceneCount}, å®Ÿéš›=${scenes.length}`);
        console.warn(`ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ã‚ˆã‚Šå¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ï¼ˆnova-2-lite, gpt-oss-20bï¼‰ã‚’è©¦ã™ã‹ã€ã‚·ãƒ¼ãƒ³æ•°ã‚’æ¸›ã‚‰ã—ã¦ãã ã•ã„`);
        
        // ä¸è¶³ã‚·ãƒ¼ãƒ³æ•°ãŒå°‘ãªã„å ´åˆã¯è¨±å®¹ï¼ˆ80%ä»¥ä¸Šï¼‰
        const completionRate = scenes.length / sceneCount;
        if (completionRate < 0.8) {
          throw new Error(`ç”Ÿæˆã‚·ãƒ¼ãƒ³æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ (${scenes.length}/${sceneCount}ã‚·ãƒ¼ãƒ³ = ${Math.round(completionRate * 100)}%)ã€‚åˆ¥ã®AIãƒ¢ãƒ‡ãƒ«ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚`);
        } else {
          console.warn(`âš ï¸ ${Math.round(completionRate * 100)}%å®Œäº† - å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™ãŒã€å®Œå…¨ã§ã¯ã‚ã‚Šã¾ã›ã‚“`);
        }
      }

      // å„ã‚·ãƒ¼ãƒ³ã®å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
      scenes.forEach((scene, index) => {
        if (!scene.scene || !scene.timestamp || !scene.prompt) {
          throw new Error(`Scene ${index + 1} is missing required fields`);
        }
        
        // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
        if (!scene.duration_seconds) {
          scene.duration_seconds = 4;
        }
        if (!scene.negative_prompt) {
          scene.negative_prompt = 'blurry, low quality, distorted, deformed, ugly, static, messy, amateur';
        }
      });

      return scenes;

    } catch (error: any) {
      console.error(`âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ (è©¦è¡Œ ${attempt + 1}):`, error.message);
      
      // ãƒªãƒˆãƒ©ã‚¤å¯èƒ½ãªã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯æ¬¡ã®è©¦è¡Œã¸
      if (attempt < maxRetries && (error.message.includes('429') || error.message.includes('timeout'))) {
        lastError = error;
        console.log(`â³ ${retryDelay/1000}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...`);
        continue;
      }
      
      // ãƒªãƒˆãƒ©ã‚¤ä¸å¯èƒ½ãªã‚¨ãƒ©ãƒ¼ã¾ãŸã¯æœ€çµ‚è©¦è¡Œ
      console.error('âŒ Video prompt generation error:', error);
      throw error;
    }
  }

  // ã™ã¹ã¦ã®ãƒªãƒˆãƒ©ã‚¤ãŒå¤±æ•—ã—ãŸå ´åˆ
  console.error('âŒ All retry attempts failed:', lastError);
  throw lastError || new Error('å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ');
}

/**
 * ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¨ˆç®—
 */
export function calculateTimestamps(scenes: VideoScene[]): VideoScene[] {
  let currentTime = 0;
  
  return scenes.map(scene => {
    const duration = scene.duration_seconds || 5;
    const startMinutes = Math.floor(currentTime / 60);
    const startSeconds = currentTime % 60;
    const endTime = currentTime + duration;
    const endMinutes = Math.floor(endTime / 60);
    const endSeconds = endTime % 60;
    
    const timestamp = `${startMinutes}:${String(startSeconds).padStart(2, '0')}-${endMinutes}:${String(endSeconds).padStart(2, '0')}`;
    
    currentTime = endTime;
    
    return {
      ...scene,
      timestamp
    };
  });
}
